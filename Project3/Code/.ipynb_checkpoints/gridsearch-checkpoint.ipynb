{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dense' from 'keras' (/home/student/anaconda3/envs/fysstk/lib/python3.7/site-packages/keras/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-990c02776f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'dense' from 'keras' (/home/student/anaconda3/envs/fysstk/lib/python3.7/site-packages/keras/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.preprocessing as sklpre\n",
    "import sklearn.model_selection as sklms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "np.random.seed(3) \n",
    "\n",
    "\n",
    "df = pd.read_csv(\"winequality-white.csv\", sep=\";\")\n",
    "X = df.drop(\"quality\", axis=1)\n",
    "y = df[\"quality\"]\n",
    "\n",
    "# stratified split\n",
    "X_train, X_test, y_train, y_test = sklms.train_test_split(\n",
    "    X, y, stratify=y, test_size=0.33\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process data\n",
    "scaler = sklpre.MinMaxScaler()  # alternative: StandardScaler()\n",
    "encoder = sklpre.OneHotEncoder(categories=\"auto\", sparse=False)  # onehot-encoder\n",
    "\n",
    "# Scale design matrix (no categorical)\n",
    "X_train = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train.to_numpy()), columns=X_train.columns\n",
    ")  # to_numpy not needed?\n",
    "\n",
    "X_test = pd.DataFrame(\n",
    "    scaler.fit_transform(X_test.to_numpy()), columns=X_test.columns\n",
    ")  # to_numpy not needed?\n",
    "\n",
    "y_train =y_train = pd.DataFrame(\n",
    "    encoder.fit_transform(y_train.to_numpy().reshape(-1, 1)),\n",
    "    columns=encoder.categories_,\n",
    ")\n",
    "\n",
    "y_test = pd.DataFrame(\n",
    "    encoder.fit_transform(y_test.to_numpy().reshape(-1, 1)), columns=encoder.categories_\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    nl1=0,\n",
    "    nl2=1,\n",
    "    nl3=0,\n",
    "    nn1=12,\n",
    "    nn2=11,\n",
    "    nn3=10,\n",
    "    lr=0.01,\n",
    "    decay=0.0,\n",
    "    l1=0.01,\n",
    "    l2=0.01,\n",
    "    act=\"relu\",\n",
    "    dropout=0,\n",
    "    input_shape=11,\n",
    "    output_shape=7, #synes jo ikke på putput!\n",
    "):\n",
    "    # set optimizer\n",
    "    opt = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, decay=decay) #decay?\n",
    "    # set regularizers\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "        Dense(nn1, input_dim=input_shape, activation=act, kernel_regularizer=reg) #dropout her?\n",
    "    )  # first layer\n",
    "    if dropout != 0:\n",
    "        model.add(Dropout(dropout))\n",
    "    for i in range(nl1):  # add up to nl1 layers with nn1 nodes\n",
    "        model.add(Dense(nn1, activation=act, kernel_regularizer=reg))\n",
    "        if dropout != 0:\n",
    "            model.add(Dropout(dropout)) #hva er egentlig dropout? Hvor lav terskel for å fjerne nevroner?\n",
    "\n",
    "    for i in range(nl2):  # add up to nl2 layers with nn2 nodes\n",
    "        model.add(Dense(nn2, activation=act, kernel_regularizer=reg))\n",
    "        if dropout != 0:\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "    for i in range(nl3):  # add up to nl3 layers with nn3 nodes\n",
    "        model.add(Dense(nn3, activation=act, kernel_regularizer=reg))\n",
    "        if dropout != 0:\n",
    "            model.add(Dropout(dropout)) #dropout her?\n",
    "    model.add(Dense(output_shape, activation=\"softmax\"))  # ouput layer\n",
    "    if dropout != 0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \"\"\"remember to change metric.\n",
    "    What is the function of metrics in compile, other than being metric for ex randomizedsearch if no metric is specified?\n",
    "    dropout on first and last layer?\n",
    "    \"\"\"\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "lr = [1e-2, 1e-3]  # , 1e-4]\n",
    "# deacy ???\n",
    "decay = [1e-6, 1e-9]  # ,0]\n",
    "\n",
    "# activation\n",
    "activation = [\"relu\", \"sigmoid\"]\n",
    "\n",
    "# numbers of layers\n",
    "nl1 = [0, 1]  # ,2]\n",
    "nl2 = [0, 1]  # ,2]\n",
    "nl3 = [0]  # ,1]#,2]\n",
    "\n",
    "# neurons in each layer\n",
    "nn1 = [12]  # ,8]#,20]\n",
    "nn2 = [11]  # ,8]#,14]\n",
    "nn3 = [10, 6]  # ,9]\n",
    "\n",
    "# dropout and regularisation\n",
    "dropout = [0, 0.1, 0.2, 0.3]\n",
    "l1 = [0, 0.01, 0.003, 0.001, 0.0001]\n",
    "l2 = [0, 0.01, 0.003, 0.001, 0.0001]\n",
    "\n",
    "dropout = [0.1, 0.2]\n",
    "l1 = [0]  # ,0.1]\n",
    "l2 = [0]  # ,0.1]\n",
    "# dictionary summary\n",
    "\n",
    "epochs=[2,3]\n",
    "\n",
    "param_grid = dict(\n",
    "    nl1=nl1,\n",
    "    nl2=nl2,\n",
    "    nl3=nl3,\n",
    "    nn1=nn1,\n",
    "    nn2=nn2,\n",
    "    nn3=nn3,\n",
    "    act=activation,\n",
    "    l1=l1,\n",
    "    l2=l2,\n",
    "    lr=lr,\n",
    "    decay=decay,\n",
    "    dropout=dropout,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7a6e1fc8583f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fysstk/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fysstk/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 **self.filter_sk_params(self.build_fn.__call__))\n\u001b[1;32m    141\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         if (losses.is_categorical_crossentropy(self.model.loss) and\n",
      "\u001b[0;32m<ipython-input-10-62deefaa793f>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(nl1, nl2, nl3, nn1, nn2, nn3, lr, decay, l1, l2, act, dropout, input_shape, output_shape)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     model.add(\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#dropout her?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     )  # first layer\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dense' is not defined"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "model.fit(X_train.values, y_train.values)\n",
    "ypred=model.predict_proba(X_train.values, verbose=1) \n",
    "print(ypred)\n",
    "print(y_train)\n",
    "print(np.shape(ypred),np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c128356ffaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m grid = sklms.RandomizedSearchCV(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msklms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "grid = sklms.RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    cv=sklms.KFold(3),\n",
    "    param_distributions=param_grid,\n",
    "    verbose=1,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_weighted\"\n",
    ")  # scoring='f1_weighted') - default uses estimator scoring\n",
    "grid_result = grid.fit(X_train.values, np.argmax(y_train.values,axis=1))\n",
    "cv_results_df = pd.DataFrame(grid_result.cv_results_)\n",
    "cv_results_df.to_csv(\"gridsearch.csv\")\n",
    "\n",
    "best_params = grid_result.best_params_\n",
    "best_model = grid_result.best_estimator_\n",
    "\n",
    "print(\"Best fit params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
