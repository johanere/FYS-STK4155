{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.preprocessing as sklpre\n",
    "import sklearn.model_selection as sklms\n",
    "import sklearn.metrics as sklmet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.preprocessing as sklpre\n",
    "import sklearn.model_selection as sklms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def load_wine_split(wine=1):\n",
    "    if wine==1:\n",
    "        data=\"winequality-white.csv\"\n",
    "    elif wine==2:\n",
    "        data=\"winequality-white.csv\",\n",
    "    else:\n",
    "        exit('Program aborted. Provide wine type 1 (white) or 2 (red) in function load_wine_split')\n",
    "    df = pd.read_csv(data, sep=\";\")\n",
    "    X = df.drop(\"quality\", axis=1)\n",
    "    y = df[\"quality\"]\n",
    "\n",
    "    # stratified split\n",
    "    X_train, X_test, y_train, y_test = sklms.train_test_split(\n",
    "        X, y, stratify=y, test_size=0.33\n",
    "    )\n",
    "\n",
    "    # pre-process data\n",
    "    scaler = sklpre.MinMaxScaler()  # alternative: StandardScaler()\n",
    "    encoder = sklpre.OneHotEncoder(categories=\"auto\", sparse=False)  # onehot-encoder\n",
    "\n",
    "    # Scale design matrix (no categorical)\n",
    "    X_train = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train.to_numpy()), columns=X_train.columns\n",
    "    )  # to_numpy not needed?\n",
    "\n",
    "    X_test = pd.DataFrame(\n",
    "        scaler.fit_transform(X_test.to_numpy()), columns=X_test.columns\n",
    "    )  # to_numpy not needed?\n",
    "\n",
    "    y_train  = pd.DataFrame(\n",
    "        encoder.fit_transform(y_train.to_numpy().reshape(-1, 1)),\n",
    "        columns=encoder.categories_,\n",
    "    )\n",
    "\n",
    "    y_test = pd.DataFrame(\n",
    "        encoder.fit_transform(y_test.to_numpy().reshape(-1, 1)), columns=encoder.categories_\n",
    "    )\n",
    "\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "\n",
    "from keras import optimizers as kerasopt\n",
    "from keras import regularizers as kerasreg\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "def create_model(\n",
    "    nl1=0,\n",
    "    nl2=1,\n",
    "    nl3=0,\n",
    "    nn1=12,\n",
    "    nn2=11,\n",
    "    nn3=10,\n",
    "    lr=0.01,\n",
    "    decay=0.0,\n",
    "    l1=0.01,\n",
    "    l2=0.01,\n",
    "    act=\"relu\",\n",
    "    dropout=0,\n",
    "    input_shape=11,\n",
    "    output_shape=7, #synes jo ikke på putput!\n",
    "):\n",
    "    # set optimizer\n",
    "    opt = kerasopt.Adam(lr=lr, beta_1=0.9, beta_2=0.999, decay=decay) #decay?\n",
    "    # set regularizers\n",
    "    reg = kerasreg.l1_l2(l1=l1, l2=l2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(nn1, input_dim=input_shape, activation=act, kernel_regularizer=reg) #dropout her?\n",
    "    )  # first layer\n",
    "    if dropout != 0:\n",
    "        model.add(Dropout(dropout))\n",
    "    for i in range(nl1):  # add up to nl1 layers with nn1 nodes\n",
    "        model.add(Dense(nn1, activation=act, kernel_regularizer=reg))\n",
    "        if dropout != 0:\n",
    "            model.add(Dropout(dropout)) #hva er egentlig dropout? Hvor lav terskel for å fjerne nevroner?\n",
    "\n",
    "    for i in range(nl2):  # add up to nl2 layers with nn2 nodes\n",
    "        model.add(Dense(nn2, activation=act, kernel_regularizer=reg))\n",
    "        if dropout != 0:\n",
    "            model.add(Dropout(dropout))\n",
    "\n",
    "    for i in range(nl3):  # add up to nl3 layers with nn3 nodes\n",
    "        model.add(Dense(nn3, activation=act, kernel_regularizer=reg))\n",
    "        if dropout != 0:\n",
    "            model.add(Dropout(dropout)) #dropout her?\n",
    "    model.add(Dense(output_shape, activation=\"softmax\"))  # ouput layer\n",
    "    if dropout != 0:\n",
    "        model.add(Dropout(dropout))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "np.random.seed(3)\n",
    "X_train,X_test,y_train,y_test=load_wine_split(wine=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "lr = [1e-2, 1e-3]  # , 1e-4] # learning rate\n",
    "decay = [1e-6, 1e-9]  # ,0] # deacy\n",
    "activation = [\"relu\", \"sigmoid\"] # activation\n",
    "\n",
    "nl1 = [0, 1]  # ,2] # numbers of layers of type nl1\n",
    "nl2 = [0, 1]  # ,2] # numbers of layers of type nl2\n",
    "nl3 = [0]  # ,1]#,2] # numbers of layers of type nl3\n",
    "\n",
    "nn1 = [12]  # ,8]#,20] # neurons in each layer of type nl1\n",
    "nn2 = [11]  # ,8]#,14] # neurons in each layer of type nl2\n",
    "nn3 = [10, 6]  # ,9] # neurons in each layer of type nl3\n",
    "\n",
    "dropout = [0, 0.1, 0.2, 0.3] #dropout\n",
    "l1 = [0, 0.01, 0.003, 0.001, 0.0001] #Regularizer 1\n",
    "l2 = [0, 0.01, 0.003, 0.001, 0.0001] #Regularizer 2\n",
    "\n",
    "dropout = [0.1, 0.2]\n",
    "l1 = [0]  # ,0.1]\n",
    "l2 = [0]  # ,0.1]\n",
    "\n",
    "epochs=[2,3]\n",
    "\n",
    "param_grid = dict(\n",
    "    nl1=nl1,\n",
    "    nl2=nl2,\n",
    "    nl3=nl3,\n",
    "    nn1=nn1,\n",
    "    nn2=nn2,\n",
    "    nn3=nn3,\n",
    "    act=activation,\n",
    "    l1=l1,\n",
    "    l2=l2,\n",
    "    lr=lr,\n",
    "    decay=decay,\n",
    "    dropout=dropout,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import optimizers as kerasopt\n",
    "from keras import regularizers as kerasreg\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   18.3s finished\n",
      "/home/student/anaconda3/envs/fysstk/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3281/3281 [==============================] - 1s 363us/step - loss: 2.7038 - accuracy: 0.4410\n",
      "Epoch 2/3\n",
      "3281/3281 [==============================] - 1s 272us/step - loss: 2.4435 - accuracy: 0.4861\n",
      "Epoch 3/3\n",
      "3281/3281 [==============================] - 1s 291us/step - loss: 2.6229 - accuracy: 0.4858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid = sklms.RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    cv=sklms.KFold(3),\n",
    "    param_distributions=param_grid,\n",
    "    verbose=1,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_absolute_error'\n",
    ") #GridSearchCV\n",
    "grid_result = grid.fit(X_train.values, np.argmax(y_train.values,axis=1))\n",
    "cv_results_df = pd.DataFrame(grid_result.cv_results_)\n",
    "cv_results_df.to_csv(\"gridsearch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fit params: {'nn3': 6, 'nn2': 11, 'nn1': 12, 'nl3': 0, 'nl2': 0, 'nl1': 0, 'lr': 0.01, 'l2': 0, 'l1': 0, 'epochs': 3, 'dropout': 0.1, 'decay': 1e-06, 'act': 'relu'}\n",
      "Best score: -0.5586711368485218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params = grid_result.best_params_\n",
    "best_model = grid_result.best_estimator_\n",
    "best_score= grid_result.best_score_\n",
    "print(\"Best fit params:\", best_params)\n",
    "print('Best score:', best_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAD 0.5748247485522706\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred=best_model.predict(X_train.to_numpy(), verbose=0)\n",
    "y_train_1=np.argmax(y_train.values,axis=1)\n",
    "\n",
    "\n",
    "f1_best=mean_absolute_error(y_train_1,y_pred)\n",
    "print(\"Best MAD\", f1_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
